{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCGA Project Setup\n",
    "\n",
    "This notebook initializes the TCGA project by:\n",
    "- Loading and validating configuration\n",
    "- Creating Unity Catalog resources (catalog, schema, volume)\n",
    "- Setting up Databricks widgets for runtime configuration\n",
    "- Exporting variables for use in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import configuration manager\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('.')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from config.config_manager import load_config\n",
    "\n",
    "# Load configuration\n",
    "# Use environment variable to specify environment (dev, staging, production)\n",
    "environment = os.getenv('TCGA_ENVIRONMENT', 'production')\n",
    "print(f\"Loading configuration for environment: {environment}\")\n",
    "\n",
    "config = load_config(environment=environment)\n",
    "print(f\"Configuration loaded successfully: {config}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create Databricks widgets for runtime configuration\n",
    "config.get_databricks_widgets(dbutils)\n",
    "\n",
    "# Export commonly used variables\n",
    "catalog = config.lakehouse.catalog\n",
    "schema = config.lakehouse.schema\n",
    "volume = config.lakehouse.volume\n",
    "volume_path = config.lakehouse.volume_path\n",
    "database_name = config.lakehouse.database_name\n",
    "\n",
    "# API endpoints\n",
    "cases_endpt = config.api.cases_endpt\n",
    "files_endpt = config.api.files_endpt\n",
    "data_endpt = config.api.data_endpt\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\"*60)\n",
    "print(\"TCGA Project Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Schema: {schema}\")\n",
    "print(f\"Volume: {volume}\")\n",
    "print(f\"Volume Path: {volume_path}\")\n",
    "print(f\"Database: {database_name}\")\n",
    "print(f\"\")\n",
    "print(f\"API Endpoints:\")\n",
    "print(f\"  Cases: {cases_endpt}\")\n",
    "print(f\"  Files: {files_endpt}\")\n",
    "print(f\"  Data: {data_endpt}\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unity Catalog Resources\n",
    "\n",
    "Create the catalog, schema, and volume if they don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Note: Uncomment the line below to create catalog (requires appropriate permissions)\n",
    "# spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")\n",
    "\n",
    "# Create schema if not exists\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "print(f\"✓ Schema {catalog}.{schema} created or already exists\")\n",
    "\n",
    "# Create volume if not exists  \n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog}.{schema}.{volume}\")\n",
    "print(f\"✓ Volume {catalog}.{schema}.{volume} created or already exists\")\n",
    "\n",
    "print(f\"\\nSetup complete! Unity Catalog resources are ready.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Setup\n",
    "\n",
    "Verify that the resources were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verify schema exists\n",
    "schemas_df = spark.sql(f\"SHOW SCHEMAS IN {catalog}\")\n",
    "print(f\"Schemas in {catalog}:\")\n",
    "display(schemas_df)\n",
    "\n",
    "# Verify volume exists\n",
    "volumes_df = spark.sql(f\"SHOW VOLUMES IN {catalog}.{schema}\")\n",
    "print(f\"\\nVolumes in {catalog}.{schema}:\")\n",
    "display(volumes_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run `01-data-download` to download TCGA data from GDC API\n",
    "2. Run DLT pipeline to create managed tables\n",
    "3. Run `02-tcga-expression-clustering` for analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
